from lm_eval.api.instance import Instance
from lm_eval.tasks.squadv2.task import SQuAD2


class SlovakSquad(SQuAD2):
    VERSION = 1  # Set a new version number for the Slovak task
    DATASET_PATH = "TUKE-DeutscheTelekom/squad-sk"
    LMT_ROWS = None  # for debugging purposes only.

    def __init__(self, config=None):
        super().__init__(config=config)

    def training_docs(self):
        if self.LMT_ROWS:
            return self.dataset["train"].select(range(self.LMT_ROWS))
        return self.dataset["train"]

    def validation_docs(self):
        if self.LMT_ROWS:
            return self.dataset["validation"].select(range(self.LMT_ROWS))
        return self.dataset["validation"]

    def construct_requests(self, doc, ctx, **kwargs):
        """Uses RequestFactory to construct Requests and returns an iterable of
        Requests which will be sent to the LM.

        :param doc:
            The document as returned from training_docs, validation_docs, or test_docs.
        :param ctx: str
            The context string, generated by fewshot_context. This includes the natural
            language description, as well as the few shot examples, and the question
            part of the document for `doc`.
        """
        metadata = "squad-sk", doc["id"], 1

        return [
            Instance(
                request_type="generate_until",
                doc=doc,
                arguments=(ctx, {"until": ["\n"]}),
                idx=0,
                metadata=metadata,
            ),
            Instance(
                request_type="loglikelihood",
                doc=doc,
                arguments=(ctx, " " + "unanswerable"),
                idx=0,
                metadata=metadata,
            ),
        ]
